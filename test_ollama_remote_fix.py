#!/usr/bin/env python3
"""
æµ‹è¯•è¿œç¨‹Ollamaè¿æ¥é…ç½®ä¿®å¤
éªŒè¯æ˜¯å¦æ­£ç¡®è¿æ¥åˆ°è¿œç¨‹æœåŠ¡è€Œä¸æ˜¯æœ¬åœ°æœåŠ¡
"""

import os
import sys
import requests
import logging
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def test_environment_setup():
    """æµ‹è¯•ç¯å¢ƒå˜é‡è®¾ç½®"""
    print("=" * 60)
    print("ç¯å¢ƒå˜é‡é…ç½®æ£€æŸ¥")
    print("=" * 60)
    
    # å¼ºåˆ¶è®¾ç½®è¿œç¨‹æœåŠ¡é…ç½®ï¼ˆé˜²æ­¢æœ¬åœ°æœåŠ¡å¯åŠ¨ï¼‰
    remote_host = 'http://120.232.79.82:11434'
    os.environ['OLLAMA_HOST'] = remote_host
    os.environ['OLLAMA_BASE_URL'] = remote_host
    os.environ['OLLAMA_NO_SERVE'] = '1'
    os.environ['OLLAMA_ORIGINS'] = '*'
    os.environ['LLM_BINDING_HOST'] = remote_host
    os.environ['LLM_MODEL'] = 'llama3.2:latest'
    os.environ['EMBEDDING_MODEL'] = 'bge-m3:latest'
    
    env_vars = [
        'OLLAMA_HOST',
        'OLLAMA_BASE_URL', 
        'OLLAMA_NO_SERVE',
        'LLM_BINDING_HOST',
        'LLM_MODEL',
        'EMBEDDING_MODEL'
    ]
    
    for var in env_vars:
        value = os.environ.get(var, 'NOT SET')
        print(f"  {var}: {value}")
    
    print(f"\nâœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆï¼Œè¿œç¨‹åœ°å€: {remote_host}")
    return remote_host

def test_direct_api_call(host):
    """ç›´æ¥æµ‹è¯•APIè°ƒç”¨"""
    print("\n" + "=" * 60)
    print("ç›´æ¥APIè°ƒç”¨æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•æœåŠ¡å¯ç”¨æ€§
        print(f"1. æµ‹è¯•æœåŠ¡å¯ç”¨æ€§: {host}/api/tags")
        response = requests.get(f"{host}/api/tags", timeout=10)
        print(f"   çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("   âœ… è¿œç¨‹OllamaæœåŠ¡å¯ç”¨")
            
            # æµ‹è¯•åµŒå…¥API
            print(f"\n2. æµ‹è¯•åµŒå…¥API: {host}/api/embed")
            embed_payload = {
                "model": "bge-m3:latest",
                "input": "æµ‹è¯•æ–‡æœ¬"
            }
            
            embed_response = requests.post(
                f"{host}/api/embed", 
                json=embed_payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            print(f"   çŠ¶æ€ç : {embed_response.status_code}")
            if embed_response.status_code == 200:
                embed_data = embed_response.json()
                if 'embeddings' in embed_data or 'embedding' in embed_data:
                    print("   âœ… åµŒå…¥APIæ­£å¸¸å·¥ä½œ")
                    return True
                else:
                    print(f"   âŒ åµŒå…¥APIå“åº”æ ¼å¼å¼‚å¸¸: {embed_data}")
            else:
                print(f"   âŒ åµŒå…¥APIè°ƒç”¨å¤±è´¥: {embed_response.text}")
        else:
            print(f"   âŒ è¿œç¨‹OllamaæœåŠ¡ä¸å¯ç”¨: {response.text}")
    
    except requests.exceptions.RequestException as e:
        print(f"   âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
    
    return False

def test_ollama_api_direct():
    """æµ‹è¯•ollama HTTP APIç›´æ¥è°ƒç”¨æ˜¯å¦æ­£ç¡®é…ç½®"""
    print("\n" + "=" * 60)
    print("Ollama HTTP APIç›´æ¥è°ƒç”¨æµ‹è¯•")
    print("=" * 60)
    
    try:
        remote_host = os.environ.get('OLLAMA_HOST')
        print(f"ä½¿ç”¨åœ°å€: {remote_host}")
        
        # æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆHTTP APIï¼‰
        print("è·å–æ¨¡å‹åˆ—è¡¨...")
        response = requests.get(f"{remote_host}/api/tags", timeout=10)
        
        if response.status_code == 200:
            models_data = response.json()
            models = models_data.get('models', [])
            model_names = [m.get('name', str(m)) for m in models]
            
            print(f"å¯ç”¨æ¨¡å‹: {model_names}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆ‘ä»¬éœ€è¦çš„æ¨¡å‹
            target_models = ['llama3.2:latest', 'bge-m3:latest']
            for target in target_models:
                found = any(target.lower() in name.lower() for name in model_names)
                status = "âœ…" if found else "âš ï¸"
                print(f"  {status} {target}: {'æ‰¾åˆ°' if found else 'æœªæ‰¾åˆ°'}")
            
            # æµ‹è¯•æ–‡æœ¬ç”ŸæˆAPI
            print("\næµ‹è¯•æ–‡æœ¬ç”ŸæˆAPI...")
            generate_payload = {
                "model": "llama3.2:latest",
                "prompt": "ç®€å•å›ç­”ï¼šä½ å¥½",
                "stream": False
            }
            
            gen_response = requests.post(
                f"{remote_host}/api/generate",
                json=generate_payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if gen_response.status_code == 200:
                gen_data = gen_response.json()
                generated_text = gen_data.get('response', '')
                print(f"  âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ: {generated_text[:50]}...")
            else:
                print(f"  âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥: HTTP {gen_response.status_code}")
            
            return True
        else:
            print(f"âŒ æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥: HTTP {response.status_code}")
            return False
        
    except Exception as e:
        print(f"âŒ HTTP APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_entity_extractor():
    """æµ‹è¯•å®ä½“æå–å™¨é…ç½®"""
    print("\n" + "=" * 60)
    print("å®ä½“æå–å™¨é…ç½®æµ‹è¯•")
    print("=" * 60)
    
    try:
        from backend.entity_extractor import EntityExtractor
        
        # åˆ›å»ºå®ä½“æå–å™¨ï¼ˆä¼šè‡ªåŠ¨è®¾ç½®ç¯å¢ƒå˜é‡ï¼‰
        extractor = EntityExtractor()
        
        print(f"å®ä½“æå–å™¨Ollamaåœ°å€: {extractor.ollama_host}")
        print(f"ä½¿ç”¨æ¨¡å‹: {extractor.model_name}")
        
        # ç®€å•æµ‹è¯•ï¼ˆä¸å®é™…è°ƒç”¨ï¼Œåªæ£€æŸ¥é…ç½®ï¼‰
        expected_host = 'http://120.232.79.82:11434'
        if extractor.ollama_host == expected_host:
            print(f"âœ… å®ä½“æå–å™¨é…ç½®æ­£ç¡®")
            return True
        else:
            print(f"âŒ å®ä½“æå–å™¨é…ç½®é”™è¯¯ï¼ŒæœŸæœ›: {expected_host}, å®é™…: {extractor.ollama_host}")
            return False
    
    except Exception as e:
        print(f"âŒ å®ä½“æå–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_vector_retriever():
    """æµ‹è¯•å‘é‡æ£€ç´¢å™¨é…ç½®"""
    print("\n" + "=" * 60)
    print("å‘é‡æ£€ç´¢å™¨é…ç½®æµ‹è¯•")
    print("=" * 60)
    
    try:
        from backend.vector_retrieval import VectorRetriever
        
        # åˆ›å»ºå‘é‡æ£€ç´¢å™¨
        retriever = VectorRetriever()
        
        print(f"å‘é‡æ£€ç´¢å™¨åµŒå…¥æ¨¡å‹: {retriever.embedding_model_name}")
        print(f"Ollamaåœ°å€: {getattr(retriever, 'ollama_host', 'N/A')}")
        print(f"ä½¿ç”¨Ollama: {getattr(retriever, 'use_ollama', False)}")
        
        # æ£€æŸ¥é…ç½®
        if hasattr(retriever, 'use_ollama') and retriever.use_ollama:
            print("âœ… å‘é‡æ£€ç´¢å™¨é…ç½®ä¸ºä½¿ç”¨è¿œç¨‹Ollama")
            return True
        else:
            print("âš ï¸ å‘é‡æ£€ç´¢å™¨æœªé…ç½®ä¸ºä½¿ç”¨Ollamaï¼ˆå¯èƒ½ä½¿ç”¨å¤‡ç”¨æ¨¡å‹ï¼‰")
            return True
    
    except Exception as e:
        print(f"âŒ å‘é‡æ£€ç´¢å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”§ è¿œç¨‹Ollamaè¿æ¥é…ç½®ä¿®å¤éªŒè¯")
    print("æµ‹è¯•æ˜¯å¦æˆåŠŸä¿®å¤127.0.0.1:64482è¿æ¥é—®é¢˜")
    
    # è®°å½•æµ‹è¯•ç»“æœ
    test_results = []
    
    # 1. ç¯å¢ƒå˜é‡è®¾ç½®
    remote_host = test_environment_setup()
    
    # 2. ç›´æ¥APIè°ƒç”¨æµ‹è¯•
    api_success = test_direct_api_call(remote_host)
    test_results.append(("ç›´æ¥APIè°ƒç”¨", api_success))
    
    # 3. Ollama HTTP APIç›´æ¥æµ‹è¯•
    api_direct_success = test_ollama_api_direct()
    test_results.append(("Ollama HTTP API", api_direct_success))
    
    # 4. å®ä½“æå–å™¨æµ‹è¯•
    extractor_success = test_entity_extractor()
    test_results.append(("å®ä½“æå–å™¨", extractor_success))
    
    # 5. å‘é‡æ£€ç´¢å™¨æµ‹è¯•
    retriever_success = test_vector_retriever()
    test_results.append(("å‘é‡æ£€ç´¢å™¨", retriever_success))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    all_passed = True
    for test_name, success in test_results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if not success:
            all_passed = False
    
    print(f"\n{'ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼' if all_passed else 'âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥'}")
    
    if all_passed:
        print("è¿œç¨‹Ollamaè¿æ¥é…ç½®ä¿®å¤æˆåŠŸ")
        print("ç°åœ¨å¯ä»¥è¿è¡Œ GraphRAG å¯¼å…¥ï¼Œåº”è¯¥ä¸ä¼šå†è¿æ¥åˆ° 127.0.0.1:64482")
    else:
        print("ä»æœ‰é—®é¢˜éœ€è¦è§£å†³ï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹")
    
    return all_passed

if __name__ == "__main__":
    main()