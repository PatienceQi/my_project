# 环境配置

<cite>
**本文档中引用的文件**  
- [requirements.txt](file://requirements.txt) - *更新了依赖列表，增加了GraphRAG相关包*
- [README.md](file://README.md) - *更新了安装和配置说明*
- [backend/api_server.py](file://backend/api_server.py) - *更新了环境变量加载逻辑*
- [scripts/test_neo4j_connection.py](file://scripts/test_neo4j_connection.py) - *测试脚本保持不变*
- [scripts/test_ollama_connection.py](file://scripts/test_ollama_connection.py) - *更新为使用HTTP API进行连接测试*
- [scripts/import_policy_data.py](file://scripts/import_policy_data.py) - *数据导入脚本*
- [database/[OCR]_华侨经济文化合作试验区.json](file://database/[OCR]_华侨经济文化合作试验区.json) - *示例数据文件*
- [backend/graphrag_engine.py](file://backend/graphrag_engine.py) - *统一调整超时配置为600秒*
- [backend/vector_retrieval.py](file://backend/vector_retrieval.py) - *统一调整嵌入向量生成超时为600秒*
- [backend/connections.py](file://backend/connections.py) - *统一调整连接管理器默认超时为600秒*
- [backend/ollama_error_handler.py](file://backend/ollama_error_handler.py) - *统一调整错误处理器超时为600秒*
- [超时配置调整总结.md](file://超时配置调整总结.md) - *详细记录了所有超时配置的调整*
</cite>

## 更新摘要
**变更内容**   
- 根据最新代码变更，更新了Python依赖列表，增加了GraphRAG相关依赖
- 修正了Ollama连接测试方法，从使用ollama客户端改为直接HTTP API调用
- 更新了环境变量配置说明，强调必须使用远程Ollama服务
- 添加了对备用嵌入模型的说明
- 移除了不存在的.env.template文件相关说明
- **新增：统一将核心功能的超时配置调整为600秒，以解决Ollama服务连接超时问题**

## 目录
1. [项目概述](#项目概述)  
2. [核心依赖安装与配置](#核心依赖安装与配置)  
   2.1 [Neo4j图数据库配置](#neo4j图数据库配置)  
   2.2 [Ollama大模型服务配置](#ollama大模型服务配置)  
   2.3 [Python运行环境配置](#python运行环境配置)  
3. [环境变量配置](#环境变量配置)  
4. [服务连接测试](#服务连接测试)  
5. [常见问题排查](#常见问题排查)  
6. [验证环境就绪](#验证环境就绪)

## 项目概述

本指南旨在为用户提供从零开始搭建“政策法规RAG问答系统”所需环境的完整说明。系统依赖三大核心技术组件：Neo4j图数据库用于存储和查询政策法规的实体关系，Ollama大模型服务用于自然语言理解和生成，以及Python后端服务（基于Flask框架）作为系统集成与API接口。通过本指南，用户将能够成功配置所有依赖项，确保系统各组件正常通信，为后续的数据导入和功能使用打下坚实基础。

**Section sources**
- [README.md](file://README.md#L0-L252)

## 核心依赖安装与配置

### Neo4j图数据库配置

Neo4j是本系统的核心数据存储引擎，用于构建政策法规的图谱结构。以下是详细的安装与配置步骤。

#### 安装方式选择

根据使用场景，推荐两种安装方式：

- **Neo4j Desktop（推荐用于本地开发）**：提供图形化界面，适合初学者。
- **Neo4j命令行版本（推荐用于服务器部署）**：轻量级，适合生产环境。

#### Neo4j Desktop安装步骤

1. **下载与安装**：
   - 访问 [Neo4j下载页面](https://neo4j.com/download/)。
   - 下载并安装“Neo4j Desktop”应用程序。

2. **创建项目与数据库**：
   - 启动Neo4j Desktop，使用邮箱激活。
   - 创建新项目，命名为“政策法规RAG系统”。
   - 点击“Add” → “Local DBMS”，创建本地数据库。
   - 数据库名称设为 `policy-rag-db`。
   - 版本选择 `5.14.1` 或更高稳定版。
   - 设置密码，该密码将用于后续的`.env`文件配置。

3. **启动与验证**：
   - 在项目面板中点击“Start”按钮启动数据库。
   - 等待状态变为“Active”（绿色）。
   - 点击“Open”按钮打开Neo4j Browser，或在浏览器中访问 `http://localhost:7474`。
   - 使用设置的用户名（默认`neo4j`）和密码登录。
   - 执行测试查询 `MATCH (n) RETURN count(n);`，若返回结果，说明数据库已就绪。

#### Neo4j命令行版本安装步骤

1. **下载与解压**：
   ```bash
   # Linux/macOS
   curl -O https://dist.neo4j.org/neo4j-community-5.14.1-unix.tar.gz
   tar -xzf neo4j-community-5.14.1-unix.tar.gz
   cd neo4j-community-5.14.1
   ```

2. **配置环境变量**：
   ```bash
   # Linux/macOS
   export NEO4J_HOME=/path/to/neo4j-community-5.14.1
   export PATH=$NEO4J_HOME/bin:$PATH
   ```

3. **修改配置文件**：
   编辑 `$NEO4J_HOME/conf/neo4j.conf`，确保以下配置项：
   ```properties
   server.default_listen_address=0.0.0.0
   server.bolt.listen_address=:7687
   server.http.listen_address=:7474
   dbms.security.auth_enabled=true
   ```

4. **设置初始密码**：
   ```bash
   neo4j-admin dbms set-initial-password "your_password"
   ```

5. **启动服务**：
   ```bash
   neo4j start
   ```

6. **验证连接**：
   ```bash
   cypher-shell -a bolt://localhost:7687 -u neo4j -p your_password
   ```

**Section sources**
- [README.md](file://README.md#L50-L150)

### Ollama大模型服务配置

Ollama服务为系统提供大语言模型能力，用于生成自然语言回答和进行实体识别。

#### 安装与启动

1. **下载Ollama**：
   - 访问 [Ollama官网](https://ollama.com/) 下载并安装。

2. **启动服务**：
   ```bash
   ollama serve
   ```
   该命令将启动Ollama服务，默认监听 `11434` 端口。

3. **拉取模型**：
   推荐使用 `llama3` 系列模型：
   ```bash
   ollama pull llama3
   ollama pull llama3.2:latest
   ```

#### 远程服务配置

**重要更新**：根据最新代码实现，系统强制使用远程Ollama服务，即使配置了本地地址也会被覆盖。

- 服务地址必须为 `http://120.232.79.82:11434`
- 在 `.env` 文件中正确配置 `LLM_BINDING_HOST=http://120.232.79.82:11434`
- 系统会自动设置 `OLLAMA_HOST` 和 `OLLAMA_NO_SERVE=1` 环境变量

**Section sources**
- [README.md](file://README.md#L152-L158)
- [backend/graphrag_engine.py](file://backend/graphrag_engine.py#L52-L89)

### Python运行环境配置

Python环境是运行后端服务和脚本的基础。

#### 步骤一：创建虚拟环境

推荐使用 `conda` 创建独立的Python环境：
```bash
conda create -n rag python=3.12
conda activate rag
```
若未安装conda，可直接使用系统Python 3.12。

#### 步骤二：安装依赖

在项目根目录下，运行以下命令安装所有依赖：
```bash
pip install -r requirements.txt
```

`requirements.txt` 文件内容如下：
```txt
# 原有依赖
neo4j==5.14.1
python-dotenv==1.0.0
requests==2.31.0
flask==3.0.0
flask-cors==4.0.0
ollama==0.5.3
psutil==5.9.6

# GraphRAG新增依赖
chromadb==0.4.15
numpy==1.24.3
scikit-learn==1.3.0

# 备用嵌入模型依赖（当远程Ollama不可用时）
sentence-transformers==2.2.2
```

这些依赖包分别用于：
- `neo4j`: 连接和操作Neo4j数据库。
- `python-dotenv`: 读取`.env`环境变量文件。
- `flask`: 构建后端Web API服务。
- `ollama`: 与Ollama大模型服务进行交互。
- `chromadb`: GraphRAG模式下的向量数据库。
- `sentence-transformers`: 当远程Ollama服务不可用时的备用嵌入模型。

**Section sources**
- [requirements.txt](file://requirements.txt#L0-L20)
- [README.md](file://README.md#L25-L35)

## 环境变量配置

系统通过 `.env` 文件集中管理配置参数。在项目根目录下创建 `.env` 文件，并填入以下内容：

```env
NEO4J_URI=neo4j://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
LLM_BINDING=ollama
LLM_MODEL=llama3.2:latest
LLM_BINDING_HOST=http://120.232.79.82:11434
```

#### 关键参数说明

- **NEO4J_URI**: Neo4j的Bolt协议连接地址。默认为 `neo4j://localhost:7687`。
- **NEO4J_USERNAME**: Neo4j数据库用户名。默认为 `neo4j`。
- **NEO4J_PASSWORD**: Neo4j数据库密码。必须与安装时设置的密码一致。
- **LLM_BINDING**: 大模型服务绑定名称。固定为 `ollama`。
- **LLM_MODEL**: 要使用的Ollama模型名称。例如 `llama3.2:latest`。
- **LLM_BINDING_HOST**: Ollama服务的API地址。**必须设置为 `http://120.232.79.82:11434`**，系统会强制使用远程服务。

**重要提示**：系统代码中会自动设置以下环境变量，无需在`.env`文件中配置：
- `OLLAMA_HOST=http://120.232.79.82:11434`
- `OLLAMA_NO_SERVE=1`
- `OLLAMA_ORIGINS=*`

**Section sources**
- [README.md](file://README.md#L37-L48)
- [backend/api_server.py](file://backend/api_server.py#L13-L37)
- [backend/graphrag_engine.py](file://backend/graphrag_engine.py#L10-L18)

## 服务连接测试

在启动主服务前，建议先运行测试脚本验证各组件连接性。

### 测试Neo4j连接

运行以下脚本：
```bash
python scripts/test_neo4j_connection.py
```

**预期输出**：
```
Connection to Neo4j successful!
```

该脚本位于 `scripts/test_neo4j_connection.py`，其核心代码为：
```python
from neo4j import GraphDatabase
import os
import dotenv

dotenv.load_dotenv()

uri = os.getenv("NEO4J_URI")
username = os.getenv("NEO4J_USERNAME")
password = os.getenv("NEO4J_PASSWORD")

try:
    driver = GraphDatabase.driver(uri, auth=(username, password))
    print("Connection to Neo4j successful!")
    driver.close()
except Exception as e:
    print(f"Failed to connect to Neo4j: {e}")
```

**Section sources**
- [scripts/test_neo4j_connection.py](file://scripts/test_neo4j_connection.py#L0-L24)

### 测试Ollama连接

**重要更新**：测试脚本已更新为使用HTTP API直接调用，而非ollama客户端。

运行以下脚本：
```bash
python scripts/test_ollama_connection.py
```

**预期输出**：
```
测试Ollama连接: http://120.232.79.82:11434
使用模型: llama3.2:latest
Connection successful! Response from ollama:
Hello! How can I assist you today?
```

该脚本位于 `scripts/test_ollama_connection.py`，其核心代码为：
```python
import os
import requests

# Read environment variables
LLM_BINDING = os.getenv('LLM_BINDING', 'ollama')
LLM_MODEL = os.getenv('LLM_MODEL', 'llama3.2:latest')
LLM_BINDING_API_KEY = os.getenv('LLM_BINDING_API_KEY', 'your_api_key')
LLM_BINDING_HOST = os.getenv('LLM_BINDING_HOST', 'http://120.232.79.82:11434')

# 强制设置远程配置
os.environ['OLLAMA_HOST'] = LLM_BINDING_HOST
os.environ['OLLAMA_BASE_URL'] = LLM_BINDING_HOST
os.environ['OLLAMA_NO_SERVE'] = '1'
os.environ['OLLAMA_ORIGINS'] = '*'

print(f"测试Ollama连接: {LLM_BINDING_HOST}")
print(f"使用模型: {LLM_MODEL}")

# Test connection to ollama service using HTTP API
try:
    # 使用HTTP API而不是ollama客户端
    url = f"{LLM_BINDING_HOST}/api/chat"
    payload = {
        "model": LLM_MODEL,
        "messages": [
            {
                'role': 'user',
                'content': 'Hello, can you respond to me?'
            }
        ],
        "stream": False
    }
    
    headers = {"Content-Type": "application/json"}
    
    response = requests.post(url, json=payload, headers=headers, timeout=600)
    response.raise_for_status()
    
    result = response.json()
    print('Connection successful! Response from ollama:')
    print(result['message']['content'])
    
except Exception as e:
    print('Error connecting to ollama service:')
    print(e)
```

**Section sources**
- [scripts/test_ollama_connection.py](file://scripts/test_ollama_connection.py#L0-L44)

## 常见问题排查

### 连接被拒绝 (Connection Refused)

- **现象**：测试脚本报错 `Connection refused`。
- **原因**：目标服务未启动或端口未开放。
- **解决方案**：
  1. 确认Neo4j服务已启动（检查 `neo4j status`）。
  2. 确认Ollama服务地址 `http://120.232.79.82:11434` 网络可达。
  3. 检查 `.env` 文件中的端口号是否正确（Neo4j: 7687）。

### 认证失败 (Authentication Failed)

- **现象**：Neo4j连接报错 `The client is unauthorized due to authentication failure`。
- **原因**：用户名或密码错误。
- **解决方案**：
  1. 检查 `.env` 文件中的 `NEO4J_USERNAME` 和 `NEO4J_PASSWORD`。
  2. 在Neo4j Browser中使用相同凭据登录，验证是否正确。

### 模型加载超时

- **现象**：Ollama连接测试长时间无响应或超时。
- **原因**：远程服务不可用或网络问题。
- **解决方案**：
  1. 检查网络连接，确保可以访问 `http://120.232.79.82:11434`。
  2. 验证远程Ollama服务是否正常运行。
  3. 如果远程服务不可用，系统会尝试使用本地sentence-transformers作为备用方案。

### 端口冲突

- **现象**：Neo4j启动失败，提示端口被占用。
- **解决方案**：
  1. 修改 `neo4j.conf` 中的 `server.bolt.listen_address` 和 `server.http.listen_address` 为其他端口。
  2. 或使用 `netstat -an | grep 7687` 找到占用进程并终止。

**Section sources**
- [README.md](file://README.md#L130-L145)

## 验证环境就绪

完成上述所有步骤后，执行以下命令进行最终验证：

1. **确认Neo4j运行**：
   ```bash
   neo4j status
   ```

2. **确认Ollama服务可达**：
   ```bash
   curl -X POST http://120.232.79.82:11434/api/chat -H "Content-Type: application/json" -d '{"model": "llama3.2:latest", "messages": [{"role": "user", "content": "test"}], "stream": false}'
   ```

3. **运行所有测试脚本**：
   ```bash
   python scripts/test_neo4j_connection.py
   python scripts/test_ollama_connection.py
   ```

当所有测试脚本均输出成功信息时，表明系统运行环境已准备就绪，可以进行下一步的数据导入和后端服务启动。