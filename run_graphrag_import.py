#!/usr/bin/env python3
"""
ä¿®å¤åçš„GraphRAGæ•°æ®å¯¼å…¥è„šæœ¬
ä½¿ç”¨è¿œç¨‹OllamaæœåŠ¡çš„bge-m3:lateståµŒå…¥æ¨¡å‹è¿›è¡Œæ•°æ®å¯¼å…¥
åŒ…å«å®Œæ•´çš„é…ç½®éªŒè¯å’Œè¯Šæ–­åŠŸèƒ½
"""

import os
import sys
import logging
import requests
import time
import psutil
import subprocess
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®é¡¹ç›®è·¯å¾„ï¼ˆéµå¾ªé¡¹ç›®å¯åŠ¨è§„èŒƒï¼‰
project_root = Path(__file__).parent.absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è®¾ç½®è¿œç¨‹Ollamaé…ç½®å¹¶éªŒè¯
def force_remote_ollama_config():
    """å¼ºåˆ¶è®¾ç½®è¿œç¨‹Ollamaé…ç½®"""
    remote_host = 'http://120.232.79.82:11434'
    
    # è®¾ç½®æ‰€æœ‰å¯èƒ½å½±å“Ollamaè¿æ¥çš„ç¯å¢ƒå˜é‡
    config_vars = {
        'EMBEDDING_MODEL': 'bge-m3:latest',
        'LLM_BINDING_HOST': remote_host,
        'LLM_MODEL': 'llama3.2:latest',
        'LLM_BINDING': 'ollama',
        'OLLAMA_HOST': remote_host,
        'OLLAMA_BASE_URL': remote_host,
        'OLLAMA_NO_SERVE': '1',
        'OLLAMA_ORIGINS': '*',
        'OLLAMA_KEEP_ALIVE': '5m'
    }
    
    print("\nâš™ï¸  å¼ºåˆ¶è®¾ç½®è¿œç¨‹Ollamaé…ç½®...")
    for key, value in config_vars.items():
        old_value = os.environ.get(key)
        os.environ[key] = value
        if old_value != value:
            print(f"   âœ… {key}: {old_value} -> {value}")
        else:
            print(f"   âœ“ {key}: {value}")

def diagnose_ollama_connection():
    """è¯Šæ–­è¿œç¨‹Ollamaè¿æ¥çŠ¶æ€"""
    remote_host = os.environ.get('LLM_BINDING_HOST', 'http://120.232.79.82:11434')
    embedding_model = os.environ.get('EMBEDDING_MODEL', 'bge-m3:latest')
    llm_model = os.environ.get('LLM_MODEL', 'llama3.2:latest')
    
    print(f"\nğŸ” è¯Šæ–­è¿œç¨‹Ollamaè¿æ¥: {remote_host}")
    
    # 1. ç½‘ç»œè¿æ¥æµ‹è¯•
    try:
        print("   1. ç½‘ç»œè¿æ¥æµ‹è¯•...")
        response = requests.get(f"{remote_host}/api/version", timeout=10)
        if response.status_code == 200:
            version_info = response.json()
            print(f"      âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼Œç‰ˆæœ¬: {version_info.get('version', 'unknown')}")
        else:
            print(f"      âŒ æœåŠ¡å“åº”å¼‚å¸¸: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"      âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
        return False
    
    # 2. æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥
    try:
        print("   2. æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥...")
        response = requests.get(f"{remote_host}/api/tags", timeout=10)
        if response.status_code == 200:
            models_data = response.json()
            models = models_data.get('models', [])
            model_names = [m.get('name', '') for m in models]
            
            # æ£€æŸ¥åµŒå…¥æ¨¡å‹
            embedding_available = any(embedding_model in name for name in model_names)
            if embedding_available:
                print(f"      âœ… åµŒå…¥æ¨¡å‹ {embedding_model} å¯ç”¨")
            else:
                print(f"      âš ï¸  åµŒå…¥æ¨¡å‹ {embedding_model} ä¸å¯ç”¨")
                print(f"         å¯ç”¨æ¨¡å‹: {', '.join(model_names)}")
            
            # æ£€æŸ¥LLMæ¨¡å‹
            llm_available = any(llm_model in name for name in model_names)
            if llm_available:
                print(f"      âœ… LLMæ¨¡å‹ {llm_model} å¯ç”¨")
            else:
                print(f"      âš ï¸  LLMæ¨¡å‹ {llm_model} ä¸å¯ç”¨")
                print(f"         å¯ç”¨æ¨¡å‹: {', '.join(model_names)}")
            
            return embedding_available  # è‡³å°‘åµŒå…¥æ¨¡å‹å¯ç”¨
        else:
            print(f"      âŒ æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"      âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    # 3. åµŒå…¥æ¨¡å‹åŠŸèƒ½æµ‹è¯•
    try:
        print("   3. åµŒå…¥æ¨¡å‹åŠŸèƒ½æµ‹è¯•...")
        test_payload = {
            "model": embedding_model,
            "prompt": "æµ‹è¯•æ–‡æœ¬"
        }
        response = requests.post(f"{remote_host}/api/embeddings", json=test_payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            if 'embedding' in result and result['embedding']:
                print(f"      âœ… åµŒå…¥æ¨¡å‹åŠŸèƒ½æ­£å¸¸ï¼Œå‘é‡ç»´åº¦: {len(result['embedding'])}")
                return True
            else:
                print(f"      âŒ åµŒå…¥æ¨¡å‹è¿”å›ç»“æœå¼‚å¸¸")
        else:
            print(f"      âŒ åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥: HTTP {response.status_code}")
    except Exception as e:
        print(f"      âŒ åµŒå…¥æ¨¡å‹æµ‹è¯•å¼‚å¸¸: {e}")
    
    return False

def validate_environment():
    """éªŒè¯ç¯å¢ƒé…ç½®"""
    print("\nğŸ” éªŒè¯ç¯å¢ƒé…ç½®...")
    
    required_configs = {
        'LLM_BINDING_HOST': 'http://120.232.79.82:11434',
        'OLLAMA_HOST': 'http://120.232.79.82:11434',
        'OLLAMA_NO_SERVE': '1',
        'EMBEDDING_MODEL': 'bge-m3:latest'
    }
    
    all_valid = True
    for key, expected in required_configs.items():
        current = os.environ.get(key)
        if current == expected:
            print(f"   âœ… {key}: {current}")
        else:
            print(f"   âŒ {key}: {current} (æœŸæœ›: {expected})")
            all_valid = False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ¬åœ°è¿æ¥é…ç½®
    suspicious_configs = [
        ('LLM_BINDING_HOST', ['127.0.0.1', 'localhost']),
        ('OLLAMA_HOST', ['127.0.0.1', 'localhost'])
    ]
    
    for config_key, suspicious_values in suspicious_configs:
        current_value = os.environ.get(config_key, '')
        for suspicious in suspicious_values:
            if suspicious in current_value:
                print(f"   âš ï¸  æ£€æµ‹åˆ°å¯ç–‘çš„æœ¬åœ°é…ç½®: {config_key}={current_value}")
                all_valid = False
    
    return all_valid

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('graphrag_import.log', encoding='utf-8')
    ]
)

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œä¿®å¤åçš„GraphRAGæ•°æ®å¯¼å…¥"""
    
    print("="*60)
    print("GraphRAGæ•°æ®å¯¼å…¥ - ä½¿ç”¨è¿œç¨‹OllamaæœåŠ¡")
    print("="*60)
    
    # æ­¥éª¤1ï¼šå¼ºåˆ¶è®¾ç½®è¿œç¨‹é…ç½®
    force_remote_ollama_config()
    
    # æ­¥éª¤2ï¼šéªŒè¯ç¯å¢ƒé…ç½®
    if not validate_environment():
        print("\nâŒ ç¯å¢ƒé…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")
        return False
    
    # æ­¥éª¤3ï¼šè¯Šæ–­è¿œç¨‹Ollamaè¿æ¥
    if not diagnose_ollama_connection():
        print("\nâŒ è¿œç¨‹Ollamaè¿æ¥è¯Šæ–­å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¯¼å…¥")
        print("ğŸ“ è¯·æ£€æŸ¥ï¼š")
        print("   1. è¿œç¨‹æœåŠ¡åœ°å€æ˜¯å¦å¯è®¿é—®: http://120.232.79.82:11434")
        print("   2. éœ€è¦çš„æ¨¡å‹æ˜¯å¦å·²å®‰è£…: bge-m3:latest, llama3.2:latest")
        print("   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return False
    
    # æ˜¾ç¤ºæœ€ç»ˆé…ç½®ä¿¡æ¯
    print(f"\nâœ… é…ç½®éªŒè¯æˆåŠŸ")
    print(f"   åµŒå…¥æ¨¡å‹: {os.environ.get('EMBEDDING_MODEL')}")
    print(f"   OllamaæœåŠ¡: {os.environ.get('LLM_BINDING_HOST')}")
    print(f"   LLMæ¨¡å‹: {os.environ.get('LLM_MODEL')}")
    
    try:
        # å¯¼å…¥ä¿®å¤åçš„GraphRAGå¯¼å…¥å™¨
        from scripts.import_graphrag_data import GraphRAGDataImporter
        
        # åˆå§‹åŒ–å¯¼å…¥å™¨
        print("\nğŸ”„ åˆå§‹åŒ–GraphRAGå¯¼å…¥å™¨...")
        importer = GraphRAGDataImporter()
        
        print(f"   âœ… ä½¿ç”¨åµŒå…¥æ¨¡å‹: {importer.vector_retriever.embedding_model_name}")
        print(f"   âœ… å‘é‡æ•°æ®åº“è·¯å¾„: {importer.vector_retriever.persist_dir}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        print("\nğŸ“ åŠ è½½æ”¿ç­–æ–‡æ¡£æ•°æ®...")
        documents = importer.load_policy_documents()
        
        if not documents:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å…¥çš„æ–‡æ¡£")
            return False
        
        print(f"   âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # æ˜¾ç¤ºæ–‡æ¡£ç»Ÿè®¡
        print("\nğŸ“Š æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯:")
        standard_count = sum(1 for doc in documents if doc.get('source', '').endswith('.json') and not doc.get('source', '').startswith('[OCR]'))
        ocr_count = sum(1 for doc in documents if doc.get('source', '').startswith('[OCR]'))
        
        print(f"   - æ ‡å‡†æ ¼å¼æ–‡æ¡£: {standard_count}")
        print(f"   - OCRæ ¼å¼æ–‡æ¡£: {ocr_count}")
        print(f"   - æ€»ç« èŠ‚æ•°: {sum(len(doc.get('sections', [])) for doc in documents)}")
        print(f"   - æ€»å†…å®¹é•¿åº¦: {sum(len(doc.get('content', '')) for doc in documents):,} å­—ç¬¦")
        
        # è¯¢é—®æ˜¯å¦æ‰§è¡Œå®Œæ•´å¯¼å…¥
        print("\nğŸš€ å¯¼å…¥é€‰é¡¹:")
        print("   [1] ä»…å‘é‡æ•°æ®åº“å¯¼å…¥ï¼ˆå¿«é€Ÿï¼‰")
        print("   [2] å®Œæ•´GraphRAGå¯¼å…¥ï¼ˆåŒ…å«å®ä½“å…³ç³»æå–ï¼‰")
        print("   [3] è·³è¿‡å¯¼å…¥ï¼Œä»…éªŒè¯æ•°æ®æ ¼å¼ä¿®å¤")
        
        choice = input("\nè¯·é€‰æ‹©å¯¼å…¥æ–¹å¼ (1/2/3): ").strip()
        
        if choice == '1':
            print("\nğŸ”„ æ­£åœ¨æ‰§è¡Œå‘é‡æ•°æ®åº“å¯¼å…¥...")
            success = importer.vector_retriever.add_documents(documents)
            if success:
                print("âœ… å‘é‡æ•°æ®åº“å¯¼å…¥æˆåŠŸ")
                print(f"   é›†åˆç»Ÿè®¡: {importer.vector_retriever.get_collection_stats()}")
            else:
                print("âŒ å‘é‡æ•°æ®åº“å¯¼å…¥å¤±è´¥")
                
        elif choice == '2':
            print("\nğŸ”„ æ­£åœ¨æ‰§è¡Œå®Œæ•´GraphRAGå¯¼å…¥...")
            print("âš ï¸  æ³¨æ„ï¼šå®Œæ•´å¯¼å…¥å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œç‰¹åˆ«æ˜¯å®ä½“å…³ç³»æå–éƒ¨åˆ†")
            
            confirm = input("ç¡®å®šç»§ç»­å—ï¼Ÿ(y/N): ").strip().lower()
            if confirm == 'y':
                print("ğŸ”„ æ­£åœ¨æ‰§è¡Œå®Œæ•´å¯¼å…¥ï¼Œè¯·è€å¿ƒç­‰å¾…...")
                importer.import_all_data(rebuild_vector_db=True, rebuild_graph=True)
                print("âœ… å®Œæ•´GraphRAGå¯¼å…¥å®Œæˆ")
            else:
                print("å·²å–æ¶ˆå®Œæ•´å¯¼å…¥")
                
        elif choice == '3':
            print("âœ… æ•°æ®æ ¼å¼ä¿®å¤éªŒè¯å®Œæˆï¼Œè·³è¿‡å¯¼å…¥")
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè·³è¿‡å¯¼å…¥")
        
        print("\n" + "="*60)
        print("âœ… GraphRAGæ•°æ®å¯¼å…¥å®Œæˆ")
        print("="*60)
        
        return True
        
    except Exception as e:
        logging.error(f"GraphRAGæ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        
        # æä¾›è°ƒè¯•ä¿¡æ¯
        print("\nğŸ“ è°ƒè¯•ä¿¡æ¯:")
        print("1. è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–ï¼š")
        print("   pip install sentence-transformers chromadb")
        print("2. å¦‚æœä½¿ç”¨bge-m3æ¨¡å‹å¤±è´¥ï¼Œä¼šè‡ªåŠ¨å›é€€åˆ°å¤‡ç”¨æ¨¡å‹")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥ä»¥ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        print("4. è¯·ç¡®ä¿è¿œç¨‹OllamaæœåŠ¡æ­£å¸¸è¿è¡Œ")
        
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    main()